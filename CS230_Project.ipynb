{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS230_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1xSzOQBrR_0LVntqoF0CyD-iNhjIJMG4I",
      "authorship_tag": "ABX9TyOiezl7FRSfcHKzvAO8ybZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelosena/cs230/blob/master/CS230_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NYwQ14afur7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sys, os, pickle, time\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import (Input, Flatten, Dense, Conv2D, MaxPool2D,\n",
        "                                GlobalAveragePooling2D, Activation, BatchNormalization,\n",
        "                                Dropout, GRU, Bidirectional, Reshape, Lambda)\n",
        "from tensorflow.keras import backend as K\n",
        "import sys, os, pickle, time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_ChPo7H5Ckw",
        "colab_type": "code",
        "outputId": "95b4fd9a-8b74-44cb-aaba-6aff8f775cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/marcelosena/cs230\n",
        "!unzip cs230/CS230OCR/ProcessedData/KerasReady0.zip -d cs230/CS230OCR/ProcessedData/\n",
        "sys.path.append('/content/cs230/CS230OCR/NeuralNet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cs230'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 70 (delta 15), reused 58 (delta 11), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (70/70), done.\n",
            "Archive:  cs230/CS230OCR/ProcessedData/KerasReady0.zip\n",
            "  inflating: cs230/CS230OCR/ProcessedData/KerasReady0.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP_bbeRBDOG-",
        "colab_type": "code",
        "outputId": "7fd9c163-e81c-4351-a9bf-42e910260bc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path = '/content/cs230/CS230OCR/'\n",
        "from utils.inputFinland import loadImgsWithLabels, DataGen\n",
        "from utils.BasicConfig import (BATCH_SIZE, FULLCHARDICT,  INPUTSHAPE, LOGDIR, SAVEDIR)\n",
        "from utils.Callbacks import VizCallback\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpu, True)\n",
        "  logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "  print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBr4ZS_3C1uI",
        "colab_type": "text"
      },
      "source": [
        "Downloading the large keras dataset through google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxenOGIDgzsZ",
        "colab_type": "code",
        "outputId": "730498cd-a886-49b3-d7ea-be931f3a0673",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGvZGUZwg_9M",
        "colab_type": "code",
        "outputId": "24d055fa-a6f8-4615-f195-85af33503fe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip 'gdrive/My Drive/CS230/Keras_largeData/KerasReadyFull0.zip' -d cs230/CS230OCR/ProcessedData/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  gdrive/My Drive/CS230/Keras_largeData/KerasReadyFull0.zip\n",
            "  inflating: cs230/CS230OCR/ProcessedData/KerasReadyFull0.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvN7s6Y841vT",
        "colab_type": "text"
      },
      "source": [
        "CNN-RNN-CTC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5y7VGW55jud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMGWIDTH = 128\n",
        "IMGHEIGHT = 64\n",
        "CHANNELS = 1\n",
        "INPUTSHAPE =  [IMGWIDTH,IMGHEIGHT,1]\n",
        "FULLCHARDICT = {'0':0,'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9,'/':10,',':11, '+': 12, '-': 13, ' ': 14}\n",
        "CHARDICT = {'0':0,'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9,'/':10,',':11, '+': 12, '-': 13,}\n",
        "INVDICT = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '/', 11: ',', 12: '+', 13: '-'}\n",
        "DICTLENGTH = len(CHARDICT) + 1 # for the empty string\n",
        "MAXCHARLENGTH = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2v2iX5ddyRR",
        "colab_type": "text"
      },
      "source": [
        "Preparing Finish Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuQKKtnj43wK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    # the 2 is critical here since the first couple outputs of the RNN tend to be garbage:\n",
        "    y_pred = y_pred[:, 2:, :]\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "X, Y_label, Y_len,  N = loadImgsWithLabels(True)\n",
        "randomOrder = pickle.load(open(path + f'ProcessedData/orderFull.p', 'rb'))\n",
        "X = X[randomOrder]\n",
        "Y_label = Y_label[randomOrder]\n",
        "Y_len = Y_len[randomOrder]\n",
        "\n",
        "trainID = int(np.ceil(N*0.33))\n",
        "devID = trainID + int(np.ceil((N - trainID)/2))\n",
        "\n",
        "X_train = X[:trainID]\n",
        "Y_label_train = Y_label[:trainID]\n",
        "Y_len_train = Y_len[:trainID]\n",
        "\n",
        "X_dev = X[trainID:devID]\n",
        "Y_label_dev = Y_label[trainID:devID]\n",
        "Y_len_dev = Y_len[trainID:devID]\n",
        "\n",
        "X_test = X[devID:]\n",
        "Y_label_test = Y_label[devID:]\n",
        "Y_len_test = Y_len[devID:]\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_label_train)).batch(BATCH_SIZE)\n",
        "dev_dataset = tf.data.Dataset.from_tensor_slices((X_dev, Y_label_dev)).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_label_test)).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1HwKg3VKmlp",
        "colab_type": "code",
        "outputId": "dee4ab41-a3f3-44e5-a136-cd3a03a37e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.imshow(X_test[834,:,:,0].T, cmap='Greys')\n",
        "plt.show()\n",
        "print(Y_label_test[834])\n",
        "\n",
        "# try all other channels being zeros or ones"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[13. -1. -1. -1. -1. -1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_hDQUD_6twh",
        "colab_type": "text"
      },
      "source": [
        "Model Specification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGRcX9uct3PG",
        "colab_type": "code",
        "outputId": "09484115-4e8f-40f7-e8a6-d694799ce111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "# Transer Learning portion\n",
        "\n",
        "INPUTSHAPE_CHAN3 =  [IMGWIDTH,IMGHEIGHT,3]\n",
        "X_train_CHAN3 = np.repeat(X_train, 3, -1)\n",
        "\n",
        "# from tensorflow.keras.applications.vgg16 import VGG16\n",
        "# base_model = keras.applications.ResNet50(\n",
        "base_model = keras.applications.VGG19(\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape= INPUTSHAPE_CHAN3,\n",
        "    include_top=False)\n",
        "base_model.trainable = False\n",
        "base_model.summary()\n",
        "# print(base_model.get_layer(\"conv5_block3_out\").output_shape)\n",
        "# inputs = Input(name='the_input', shape=INPUTSHAPE_CHAN3)\n",
        "# inputs = base_model(inputs, training=False)\n",
        "# # # converts the output of pre-trained CNN for RGB images to grayscale\n",
        "# inputs = Lambda(lambda x : x[:,:,:,0])(inputs)\n",
        "# print(tf.shape(inputs))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 64, 3)]      0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 128, 64, 64)       1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 128, 64, 64)       36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 64, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 64, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 32, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 32, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 32, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 32, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 32, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 16, 8, 256)        0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 16, 8, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 16, 8, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 16, 8, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 16, 8, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 8, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 2, 512)         0         \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 0\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtT05PpvxqCr",
        "colab_type": "code",
        "outputId": "2e277f35-71f9-4ea3-b1fb-b19e34d67524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "## NOTE: SEQUENTIAL MODEL NOT APPROPRIATE FOR RESNET TYPE MODELS\n",
        "\n",
        "tiling = [1] * 4 \n",
        "tiling[-1] *= 3\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.Input(name = \"the_input\", shape=INPUTSHAPE))\n",
        "model.add(Lambda(lambda x : keras.backend.tile(x, tiling))\n",
        "model.add(keras.layers(base_model.layers[0]))\n",
        "model.add(base_model.layers[1])\n",
        "model.add(base_model.layers[2])\n",
        "model.add(base_model.layers[3])\n",
        "model.add(base_model.layers[4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-d4e422f856c8>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    model.add(keras.layers(base_model.layers[0]))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7sW_59_w7pk",
        "colab_type": "code",
        "outputId": "c2eaab41-fadc-4dab-a070-966cc8c77e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "################################################\n",
        "#%%\n",
        "# Layer params:   Filts K  Padding  Name\n",
        "layer_params = [ [  64, 7, 'same',  'conv1'],\n",
        "                 [  64, 5, 'same',  'conv2'],\n",
        "                 [ 128, 3, 'same',  'conv3'],\n",
        "                 [ 128, 3, 'same',  'conv4'],\n",
        "                 [ 256, 3, 'same',  'conv5'],\n",
        "                 [ 256, 3, 'same',  'conv6'],\n",
        "                 # [ 512, 3, 'same',  'conv7'],\n",
        "                 # [ 512, 3, 'same',  'conv8'],\n",
        "                 # [ 1024, 3, 'same',  'conv9'],\n",
        "                 # [ 1024, 3, 'same',  'conv10'],\n",
        "                 # [ 1024, 3, 'same',  'conv11'],\n",
        "                 ]\n",
        "wherePool = [1,3,5]\n",
        "\n",
        "# Network parameters\n",
        "kernel_size = (3, 3)\n",
        "pool_size = (2,2)\n",
        "denseSize = 128\n",
        "rnn_size = 256\n",
        "act = 'relu'\n",
        "minibatch_size = BATCH_SIZE\n",
        "\n",
        "### Transfer-Learned Conv-NN ###\n",
        "tiling = [1] * 4    # 4 dimensions: B, H, W, C\n",
        "tiling[-1] *= 3\n",
        "inputs = Input(name='the_input', shape=INPUTSHAPE)\n",
        "inner = keras.backend.tile(inputs, tiling)\n",
        "\n",
        "# inner = base_model(inner)\n",
        "\n",
        "# # only the first conv-nn part\n",
        "l1 = base_model.layers[0]\n",
        "l2 = base_model.layers[1]\n",
        "l3 = base_model.layers[2]\n",
        "l4 = base_model.layers[3]\n",
        "l5 = base_model.layers[4]\n",
        "l1.set_weights = l1.get_weights()\n",
        "l2.set_weights = l2.get_weights()\n",
        "l3.set_weights = l3.get_weights()\n",
        "l4.set_weights = l4.get_weights()\n",
        "l5.set_weights = l5.get_weights()\n",
        "\n",
        "# # Setting layers to non-trainable\n",
        "retrain = False\n",
        "l1.trainable = retrain\n",
        "l2.trainable = retrain\n",
        "l3.trainable = retrain\n",
        "l4.trainable = retrain\n",
        "l5.trainable = retrain\n",
        "inner = l1(inner)\n",
        "inner = l2(inner)\n",
        "inner = l3(inner)\n",
        "inner = l4(inner)\n",
        "inner = l5(inner)\n",
        "\n",
        "# print(len(base_model.layers))\n",
        "# ### all conv-nn parts\n",
        "# for ll in range(len(base_model.layers) - 20):\n",
        "#   if ll != 14 and ll != 17 and ll != 27 and ll != 37 and ll != 45 and ll != 49 and ll != 59 and ll != 69 and ll != 79 and ll != 87 and ll != 91 and ll != 101 and ll != 111:\n",
        "#     tmp_ll = base_model.layers[ll]\n",
        "#     tmp_ll.set_weights = base_model.layers[ll].get_weights()\n",
        "#     tmp_ll.trainable = retrain\n",
        "#     inner = tmp_ll(inner)\n",
        "\n",
        "# # converts the grayscale images to 3-channel amenable CNN\n",
        "# inner = Lambda(lambda x : np.repeat(x,3,-1))(inputs) # this does not work, need to use proper Keras syntax/functions\n",
        "\n",
        "# # converts the output of pre-trained CNN for RGB images to grayscale\n",
        "# inner = Lambda(lambda x : x[:,:,:,0])(inputs)\n",
        "\n",
        "# ### Our Conv-NN ###\n",
        "# inputs = Input(name='the_input', shape=INPUTSHAPE)\n",
        "# layer = layer_params[0]\n",
        "# inner = Conv2D(layer[0], layer[1], strides=(1,1), padding=layer[2], activation=act,\n",
        "#                      use_bias=False, kernel_initializer=\"he_normal\", name=layer[3] )(inputs)\n",
        "# inner = BatchNormalization(momentum=0.95, epsilon=1e-05, center=True, scale=True)(inner)\n",
        "\n",
        "# for i in range(1,len(layer_params)):\n",
        "#     layer = layer_params[i]\n",
        "#     inner = Conv2D(layer[0], layer[1], strides=(1,1), padding=layer[2], activation=act,\n",
        "#                      use_bias=False, kernel_initializer=\"he_normal\", name=layer[3] )(inner)\n",
        "#     inner = BatchNormalization(momentum=0.95, epsilon=1e-05, center=True, scale=True)(inner)\n",
        "\n",
        "#     if i in wherePool:\n",
        "#        inner = MaxPool2D(pool_size=pool_size, strides=(2, 2), padding='same', name=f'pool{i+1}')(inner)\n",
        "\n",
        "# conv_to_rnn_dims = ( IMGWIDTH// (pool_size[0] ** len(wherePool)) ,\n",
        "#                     (IMGHEIGHT  // (pool_size[0] ** len(wherePool))) * layer_params[-1][0]\n",
        "#                    )\n",
        "# print(conv_to_rnn_dims)\n",
        "\n",
        "inner = inner\n",
        "trOutShape = inner.shape\n",
        "print(trOutShape)\n",
        "conv_to_rnn_dims_transfer = (trOutShape[1], trOutShape[2]*trOutShape[3])\n",
        "print(conv_to_rnn_dims_transfer)\n",
        "\n",
        "inner = Reshape(target_shape=conv_to_rnn_dims_transfer, name='reshape')(inner)\n",
        "inner = Dense(denseSize, activation=act, name='dense1')(inner)\n",
        "inner = BatchNormalization(momentum=0.95, epsilon=1e-05, center=True, scale=True)(inner)\n",
        "\n",
        "# # Two layers of bidirectional GRUs\n",
        "gru_1 = Bidirectional(GRU(rnn_size, return_sequences=True, recurrent_dropout=0.5, dropout=0.5,\n",
        "            kernel_initializer='he_normal', name='gru1'), merge_mode='sum')(inner)\n",
        "gru_2 = Bidirectional(GRU(rnn_size, return_sequences=True, recurrent_dropout=0.5, dropout=0.5,\n",
        "            kernel_initializer='he_normal', name='gru2'))(gru_1)\n",
        "y_pred = Dense(DICTLENGTH, kernel_initializer='he_normal', name='densePredict', activation='softmax')(gru_2)\n",
        "\n",
        "# keras.Model(inputs=inputs, outputs=y_pred).summary()\n",
        "\n",
        "#%%\n",
        "labels = Input(name='the_labels', shape=[MAXCHARLENGTH], dtype='float32')\n",
        "input_length = Input(name='input_length',\n",
        "                     shape=[1], #IMGWIDTH// (pool_size[0] ** len(wherePool)) - 2\n",
        "                     dtype='int64')\n",
        "label_length = Input(name='label_length',\n",
        "                     shape=[1],\n",
        "                     dtype='int64')\n",
        "\n",
        "#CTC loss is implemented in a lambda layer\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,),\n",
        "    name='ctc')([y_pred, labels, input_length, label_length])\n",
        "\n",
        "sgd = keras.optimizers.SGD(learning_rate=0.02,\n",
        "          decay=1e-6,\n",
        "          momentum=0.9,\n",
        "          nesterov=True)\n",
        "model = keras.Model(inputs=[inputs, labels, input_length, label_length],\n",
        "              outputs=loss_out)\n",
        "\n",
        "# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd, metrics=[\"accuracy\"])\n",
        "test_func = K.function([inputs], [y_pred])\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 64, 32, 128)\n",
            "(64, 4096)\n",
            "WARNING:tensorflow:Layer gru1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIdQ0r_-8Z3R",
        "colab_type": "text"
      },
      "source": [
        "Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDmsPM-j8KVS",
        "colab_type": "code",
        "outputId": "6edc0fbf-2959-49ea-9787-a7025e16a639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "generatorTrain = DataGen(BATCH_SIZE,  (IMGWIDTH// (pool_size[0] ** len(wherePool))-2),\n",
        "                    X_train, Y_label_train, Y_len_train,  len(X_train), 0)\n",
        "generatorVal = DataGen(BATCH_SIZE,  (IMGWIDTH// (pool_size[0] ** len(wherePool))-2),\n",
        "                    X_dev, Y_label_dev, Y_len_dev,  len(X_dev), 0)\n",
        "generatorTest = DataGen(BATCH_SIZE,  (IMGWIDTH// (pool_size[0] ** len(wherePool))-2),\n",
        "                    X_test, Y_label_test, Y_len_test,  len(X_test), 0)\n",
        "\n",
        "#viz_cb = VizCallback(run_name, test_func, generatorVal.get_batch())\n",
        "# early_stopping= keras.callbacks.EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True)\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='acc', baseline = 0.95, min_delta = 0.1, restore_best_weights=True)\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\"bestRunning_model.hdf5\",\n",
        "                                            monitor='loss', verbose=1,\n",
        "                                            save_best_only=True, mode='auto')\n",
        "\n",
        "#%%\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "usualCallback = EarlyStopping()\n",
        "callCheck = [usualCallback, checkpoint]\n",
        "\n",
        "history = model.fit(generatorTrain.get_batch(), epochs=5,\n",
        "                       validation_data = generatorVal.get_batch(),\n",
        "                    validation_steps = len(X_dev)//BATCH_SIZE,\n",
        "                    steps_per_epoch = 20) #,\n",
        "                    # callbacks = [usualCallback])\n",
        "                    #callbacks=[viz_cb, early_stopping, checkpoint],)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "20/20 [==============================] - 24s 1s/step - loss: 14.3091 - accuracy: 0.1266 - val_loss: 67.3044 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 23s 1s/step - loss: 12.4490 - accuracy: 0.1562 - val_loss: 157.8416 - val_accuracy: 0.0015\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 23s 1s/step - loss: 11.3838 - accuracy: 0.1656 - val_loss: 19.0766 - val_accuracy: 0.1192\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 23s 1s/step - loss: 11.2345 - accuracy: 0.1391 - val_loss: 10.8731 - val_accuracy: 0.1940\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 23s 1s/step - loss: 10.8547 - accuracy: 0.1609 - val_loss: 13.4791 - val_accuracy: 0.1428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyRzGZyECe3w",
        "colab_type": "code",
        "outputId": "ae8d683b-0aa0-4144-d6ac-56ea7295d243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        }
      },
      "source": [
        "# # Test Accuracy\n",
        "# testFig = X_test[1,:,:,:]\n",
        "# testLab = Y_label_test[1,:]\n",
        "# print(X_test.shape)\n",
        "# print(Y_label_test.shape)\n",
        "# _, test_acc = model.evaluate(x = X_test, y = Y_label_test, verbose=-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2781, 128, 64, 1)\n",
            "(2781, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b35791d385cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_label_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_label_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2772\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 2774\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2704\u001b[0m         relaxed_arg_shapes)\n\u001b[1;32m   2705\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 2706\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   2707\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:941 test_function  *\n        outputs = self.distribute_strategy.run(\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:909 test_step  **\n        y_pred = self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:899 _run_internal_graph\n        assert str(id(x)) in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output Tensor(\"ctc/Identity:0\", shape=(None, 1), dtype=float32)\n"
          ]
        }
      ]
    }
  ]
}